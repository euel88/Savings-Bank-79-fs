"""
Streamlit ê¸°ë°˜ ì¬ë¬´ì •ë³´ ì¶”ì¶œê¸°
GitHub Actionsë¥¼ í†µí•´ ë°°í¬ ê°€ëŠ¥í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import pandas as pd
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from fuzzywuzzy import fuzz
import logging
from datetime import datetime
import io
import base64
import openai
import os
import json

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¬ë¬´ì •ë³´ ì¶”ì¶œê¸°",
    page_icon="ğŸ’°",
    layout="wide"
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    h1 {
        color: #1f77b4;
    }
    .extraction-stat {
        font-size: 1.2rem;
        font-weight: bold;
        padding: 0.5rem;
        background-color: #f0f2f6;
        border-radius: 0.3rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@dataclass
class AccountItem:
    """ê³„ì • í•­ëª© ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    name: str
    aliases: List[str]
    category: str
    value: Optional[str] = None
    unit: Optional[str] = None
    source: Optional[str] = None
    note_ref: Optional[str] = None


class FinancialDataExtractor:
    """ì¬ë¬´ ë°ì´í„° ì¶”ì¶œê¸° - Streamlit ë²„ì „"""
    
    def __init__(self):
        self.account_items = self._initialize_account_items()
        self.extracted_data = {}
        
    def _initialize_account_items(self) -> Dict[int, AccountItem]:
        """75ê°œ í‘œì¤€ ê³„ì • í•­ëª© ì´ˆê¸°í™”"""
        items = {
            # ê¸°ë³¸ ì •ë³´
            1: AccountItem(1, "ë‚ ì§œ", ["ê¸°ì¤€ì¼", "ê²°ì‚°ì¼", "ë³´ê³ ì„œì¼"], "ê¸°ë³¸ì •ë³´"),
            2: AccountItem(2, "ì€í–‰ëª…", ["ê¸ˆìœµê¸°ê´€ëª…", "íšŒì‚¬ëª…", "ë²•ì¸ëª…"], "ê¸°ë³¸ì •ë³´"),
            
            # ì¬ë¬´ìƒíƒœí‘œ í•­ëª©
            3: AccountItem(3, "ëŒ€ì¶œê¸ˆ", ["ëŒ€ì¶œì±„ê¶Œ", "ëŒ€ì¶œìì‚°", "ëŒ€ì¶œê¸ˆì”ì•¡"], "ì¬ë¬´ìƒíƒœí‘œ"),
            4: AccountItem(4, "ì˜ˆìˆ˜ê¸ˆ", ["ì˜ˆìˆ˜ë¶€ì±„", "ê³ ê°ì˜ˆê¸ˆ", "ì˜ˆê¸ˆ"], "ì¬ë¬´ìƒíƒœí‘œ"),
            5: AccountItem(5, "ìê¸°ìë³¸", ["ìë³¸ì´ê³„", "ì´ìë³¸", "ìˆœìì‚°"], "ì¬ë¬´ìƒíƒœí‘œ"),
            14: AccountItem(14, "ì´ìì‚°", ["ìì‚°ì´ê³„", "ì´ìì‚°", "ìì‚°í•©ê³„"], "ì¬ë¬´ìƒíƒœí‘œ"),
            15: AccountItem(15, "í˜„ê¸ˆë°ì˜ˆì¹˜ê¸ˆ", ["í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°", "í˜„ê¸ˆì˜ˆì¹˜ê¸ˆ"], "ì¬ë¬´ìƒíƒœí‘œ"),
            16: AccountItem(16, "ìœ ê°€ì¦ê¶Œ", ["íˆ¬ììì‚°", "íˆ¬ììœ ê°€ì¦ê¶Œ", "ê¸ˆìœµìì‚°"], "ì¬ë¬´ìƒíƒœí‘œ"),
            17: AccountItem(17, "ëŒ€ì¶œê¸ˆ(ìƒì„¸)", ["ëŒ€ì¶œì±„ê¶Œ", "ëŒ€ì¶œê¸ˆëª…ì„¸"], "ì¬ë¬´ìƒíƒœí‘œ"),
            18: AccountItem(18, "ëŒ€ì†ì¶©ë‹¹ê¸ˆ", ["ëŒ€ì†ì¶©ë‹¹ë¶€ì±„", "ì‹ ìš©ì†ì‹¤ì¶©ë‹¹ê¸ˆ", "ëŒ€ì¶œì†ì‹¤ì¶©ë‹¹ê¸ˆ"], "ì¬ë¬´ìƒíƒœí‘œ"),
            19: AccountItem(19, "ìœ í˜•ìì‚°", ["ìœ í˜•ìì‚°", "ê³ ì •ìì‚°", "ì„¤ë¹„ìì‚°"], "ì¬ë¬´ìƒíƒœí‘œ"),
            20: AccountItem(20, "ê¸°íƒ€ìì‚°", ["ê¸°íƒ€ìì‚°", "ê¸°íƒ€ìœ ë™ìì‚°", "ê¸°íƒ€ë¹„ìœ ë™ìì‚°"], "ì¬ë¬´ìƒíƒœí‘œ"),
            21: AccountItem(21, "ì˜ˆìˆ˜ê¸ˆ(ìƒì„¸)", ["ì˜ˆìˆ˜ê¸ˆëª…ì„¸", "ê³ ê°ì˜ˆê¸ˆëª…ì„¸"], "ì¬ë¬´ìƒíƒœí‘œ"),
            22: AccountItem(22, "ìê¸°ìë³¸(ìƒì„¸)", ["ìë³¸ê¸ˆ", "ìë³¸ì‰ì—¬ê¸ˆ", "ì´ìµì‰ì—¬ê¸ˆ"], "ì¬ë¬´ìƒíƒœí‘œ"),
            
            # ì†ìµê³„ì‚°ì„œ í•­ëª©
            6: AccountItem(6, "ì´ììˆ˜ìµ", ["ì´ììˆ˜ì…", "ëŒ€ì¶œì´ììˆ˜ìµ", "ì´ìì†Œë“"], "ì†ìµê³„ì‚°ì„œ"),
            7: AccountItem(7, "ì´ìë¹„ìš©", ["ì´ìë¹„ìš©", "ì˜ˆê¸ˆì´ìë¹„ìš©", "ì°¨ì…ì´ì"], "ì†ìµê³„ì‚°ì„œ"),
            9: AccountItem(9, "ëŒ€ì†ìƒê°ë¹„", ["ì‹ ìš©ì†ì‹¤ë¹„ìš©", "ëŒ€ì†ì¶©ë‹¹ê¸ˆì „ì…ì•¡", "ì‹ ìš©ì†ì‹¤ì¶©ë‹¹ê¸ˆì „ì…ì•¡"], "ì†ìµê³„ì‚°ì„œ"),
            10: AccountItem(10, "ë‹¹ê¸°ìˆœì´ìµ", ["ë‹¹ê¸°ìˆœì†ìµ", "ìˆœì´ìµ", "ë‹¹ê¸°ì´í¬ê´„ì´ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            24: AccountItem(24, "ì˜ì—…ìˆ˜ìµ", ["ì˜ì—…ìˆ˜ìµ", "ì´ì˜ì—…ìˆ˜ìµ", "ì˜ì—…ìˆ˜ìµí•©ê³„"], "ì†ìµê³„ì‚°ì„œ"),
            25: AccountItem(25, "ì´ììˆ˜ìµ(ìƒì„¸)", ["ëŒ€ì¶œì´ì", "ì˜ˆê¸ˆì´ì", "ìœ ê°€ì¦ê¶Œì´ì"], "ì†ìµê³„ì‚°ì„œ"),
            26: AccountItem(26, "ìœ ê°€ì¦ê¶Œ ì²˜ë¶„ì´ìµ", ["ìœ ê°€ì¦ê¶Œì²˜ë¶„ì´ìµ", "ë§¤ë§¤ì´ìµ", "íˆ¬ììì‚°ì²˜ë¶„ì´ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            27: AccountItem(27, "ëŒ€ì¶œì±„ê¶Œë§¤ê°ì´ìµ", ["ëŒ€ì¶œì±„ê¶Œë§¤ê°ì´ìµ", "ë§¤ê°ì´ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            28: AccountItem(28, "ìˆ˜ìˆ˜ë£Œìˆ˜ìµ", ["ìˆ˜ìˆ˜ë£Œìˆ˜ìµ", "ìˆ˜ìˆ˜ë£Œìˆ˜ì…", "ì„œë¹„ìŠ¤ìˆ˜ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            29: AccountItem(29, "ë°°ë‹¹ê¸ˆìˆ˜ìµ", ["ë°°ë‹¹ê¸ˆìˆ˜ìµ", "ë°°ë‹¹ìˆ˜ìµ", "íˆ¬ìë°°ë‹¹ê¸ˆ"], "ì†ìµê³„ì‚°ì„œ"),
            30: AccountItem(30, "ê¸°íƒ€ì˜ì—…ìˆ˜ìµ", ["ê¸°íƒ€ì˜ì—…ìˆ˜ìµ", "ê¸°íƒ€ìˆ˜ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            31: AccountItem(31, "ì˜ì—…ë¹„ìš©", ["ì˜ì—…ë¹„ìš©", "ì´ì˜ì—…ë¹„ìš©", "ì˜ì—…ë¹„ìš©í•©ê³„"], "ì†ìµê³„ì‚°ì„œ"),
            32: AccountItem(32, "ì´ìë¹„ìš©(ìƒì„¸)", ["ì˜ˆê¸ˆì´ì", "ì°¨ì…ê¸ˆì´ì", "ì‚¬ì±„ì´ì"], "ì†ìµê³„ì‚°ì„œ"),
            33: AccountItem(33, "ìœ ê°€ì¦ê¶Œ ì²˜ë¶„ì†ì‹¤", ["ìœ ê°€ì¦ê¶Œì²˜ë¶„ì†ì‹¤", "ë§¤ë§¤ì†ì‹¤", "íˆ¬ììì‚°ì²˜ë¶„ì†ì‹¤"], "ì†ìµê³„ì‚°ì„œ"),
            34: AccountItem(34, "ëŒ€ì¶œì±„ê¶Œë§¤ê°ì†ì‹¤", ["ëŒ€ì¶œì±„ê¶Œë§¤ê°ì†ì‹¤", "ë§¤ê°ì†ì‹¤"], "ì†ìµê³„ì‚°ì„œ"),
            35: AccountItem(35, "ìˆ˜ìˆ˜ë£Œë¹„ìš©", ["ìˆ˜ìˆ˜ë£Œë¹„ìš©", "ì§€ê¸‰ìˆ˜ìˆ˜ë£Œ", "ì„œë¹„ìŠ¤ë¹„ìš©"], "ì†ìµê³„ì‚°ì„œ"),
            36: AccountItem(36, "íŒê´€ë¹„", ["íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„", "íŒê´€ë¹„", "ì¼ë°˜ê´€ë¦¬ë¹„"], "ì†ìµê³„ì‚°ì„œ"),
            37: AccountItem(37, "ê¸°íƒ€ì˜ì—…ë¹„ìš©", ["ê¸°íƒ€ì˜ì—…ë¹„ìš©", "ê¸°íƒ€ë¹„ìš©"], "ì†ìµê³„ì‚°ì„œ"),
            38: AccountItem(38, "ì˜ì—…ì´ìµ", ["ì˜ì—…ì´ìµ", "ì˜ì—…ì†ìµ", "ì˜ì—…ì´ìµ(ì†ì‹¤)"], "ì†ìµê³„ì‚°ì„œ"),
            39: AccountItem(39, "ì˜ì—…ì™¸ìˆ˜ìµ", ["ì˜ì—…ì™¸ìˆ˜ìµ", "ê¸°íƒ€ìˆ˜ìµ", "íŠ¹ë³„ì´ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            40: AccountItem(40, "ì˜ì—…ì™¸ë¹„ìš©", ["ì˜ì—…ì™¸ë¹„ìš©", "ê¸°íƒ€ë¹„ìš©", "íŠ¹ë³„ì†ì‹¤"], "ì†ìµê³„ì‚°ì„œ"),
            41: AccountItem(41, "ë‹¹ê¸°ìˆœì´ìµ(ìƒì„¸)", ["ë²•ì¸ì„¸ì°¨ê°ì „ìˆœì´ìµ", "ë²•ì¸ì„¸ë¹„ìš©", "ë‹¹ê¸°ìˆœì´ìµ"], "ì†ìµê³„ì‚°ì„œ"),
            
            # ìœ ê°€ì¦ê¶Œ ì„¸ë¶€
            42: AccountItem(42, "ìœ ê°€ì¦ê¶Œ ì”ì•¡", ["ìœ ê°€ì¦ê¶Œì”ì•¡", "íˆ¬ììì‚°ì”ì•¡"], "ìœ ê°€ì¦ê¶Œ"),
            43: AccountItem(43, "ìœ ê°€ì¦ê¶Œ ìˆ˜ìµ", ["ìœ ê°€ì¦ê¶Œê´€ë ¨ìˆ˜ìµ", "íˆ¬ììˆ˜ìµ"], "ìœ ê°€ì¦ê¶Œ"),
            44: AccountItem(44, "ìœ ê°€ì¦ê¶Œ ì´ììˆ˜ìµ", ["ì±„ê¶Œì´ììˆ˜ìµ", "ìœ ê°€ì¦ê¶Œì´ì"], "ìœ ê°€ì¦ê¶Œ"),
            45: AccountItem(45, "ìœ ê°€ì¦ê¶Œ ì²˜ë¶„ì´ìµ(ìƒì„¸)", ["ë§¤ë§¤ì´ìµ", "ì²˜ë¶„ì´ìµë‚´ì—­"], "ìœ ê°€ì¦ê¶Œ"),
            46: AccountItem(46, "ìœ ê°€ì¦ê¶Œ ë°°ë‹¹ê¸ˆìˆ˜ìµ", ["ì£¼ì‹ë°°ë‹¹ê¸ˆ", "í€ë“œë°°ë‹¹ê¸ˆ"], "ìœ ê°€ì¦ê¶Œ"),
            47: AccountItem(47, "ì§€ë¶„ë²•í‰ê°€ì´ìµ", ["ì§€ë¶„ë²•ì´ìµ", "ê´€ê³„ê¸°ì—…íˆ¬ìì´ìµ"], "ìœ ê°€ì¦ê¶Œ"),
            48: AccountItem(48, "ìœ ê°€ì¦ê¶Œ ë¹„ìš©", ["ìœ ê°€ì¦ê¶Œê´€ë ¨ë¹„ìš©", "íˆ¬ìë¹„ìš©"], "ìœ ê°€ì¦ê¶Œ"),
            49: AccountItem(49, "ìœ ê°€ì¦ê¶Œ ì²˜ë¶„ì†ì‹¤(ìƒì„¸)", ["ë§¤ë§¤ì†ì‹¤", "ì²˜ë¶„ì†ì‹¤ë‚´ì—­"], "ìœ ê°€ì¦ê¶Œ"),
            50: AccountItem(50, "ìœ ê°€ì¦ê¶Œ í‰ê°€ì†ì‹¤", ["í‰ê°€ì†ì‹¤", "ë¯¸ì‹¤í˜„ì†ì‹¤"], "ìœ ê°€ì¦ê¶Œ"),
            51: AccountItem(51, "ìœ ê°€ì¦ê¶Œ ì†ìƒì°¨ì†", ["ì†ìƒì°¨ì†", "íˆ¬ììì‚°ì†ìƒì°¨ì†"], "ìœ ê°€ì¦ê¶Œ"),
            52: AccountItem(52, "ì§€ë¶„ë²•í‰ê°€ì†ì‹¤", ["ì§€ë¶„ë²•ì†ì‹¤", "ê´€ê³„ê¸°ì—…íˆ¬ìì†ì‹¤"], "ìœ ê°€ì¦ê¶Œ"),
            
            # ëŒ€ì¶œ ë° ì¶©ë‹¹ê¸ˆ
            53: AccountItem(53, "ì¶©ë‹¹ê¸ˆì ë¦½ë¥ ", ["ì¶©ë‹¹ê¸ˆì ë¦½ë¥ ", "ëŒ€ì†ì¶©ë‹¹ê¸ˆë¹„ìœ¨"], "ëŒ€ì¶œì¶©ë‹¹ê¸ˆ"),
            54: AccountItem(54, "ëŒ€ì¶œí‰ì”", ["ëŒ€ì¶œê¸ˆí‰ê· ì”ì•¡", "í‰ê· ëŒ€ì¶œê¸ˆ"], "ëŒ€ì¶œì¶©ë‹¹ê¸ˆ"),
            55: AccountItem(55, "ëŒ€ì¶œì±„ê¶Œë§¤ê°ì´ìµ(A)", ["ë§¤ê°ì´ìµA", "ëŒ€ì¶œë§¤ê°ìˆ˜ìµ"], "ëŒ€ì¶œì¶©ë‹¹ê¸ˆ"),
            56: AccountItem(56, "ëŒ€ì¶œì±„ê¶Œë§¤ê°ì†ì‹¤(B)", ["ë§¤ê°ì†ì‹¤B", "ëŒ€ì¶œë§¤ê°ë¹„ìš©"], "ëŒ€ì¶œì¶©ë‹¹ê¸ˆ"),
            57: AccountItem(57, "ì‹¤ì§ˆëŒ€ì†ìƒê°ë¹„(B-A)", ["ìˆœëŒ€ì†ìƒê°ë¹„", "ì‹¤ì§ˆëŒ€ì†ë¹„ìš©"], "ëŒ€ì¶œì¶©ë‹¹ê¸ˆ"),
            
            # ê²½ë¹„ ì„¸ë¶€
            59: AccountItem(59, "ê²½ë¹„ ì´ê³„", ["íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„", "ì´ê²½ë¹„", "ì˜ì—…ê²½ë¹„"], "ê²½ë¹„"),
            60: AccountItem(60, "ê´‘ê³ ì„ ì „ë¹„", ["ê´‘ê³ ë¹„", "ë§ˆì¼€íŒ…ë¹„ìš©", "í™ë³´ë¹„"], "ê²½ë¹„"),
            61: AccountItem(61, "ì „ì‚°ì—…ë¬´ë¹„", ["ITë¹„ìš©", "ì „ì‚°ë¹„", "ì‹œìŠ¤í…œìš´ì˜ë¹„"], "ê²½ë¹„"),
            62: AccountItem(62, "ìš©ì—­ë¹„", ["ì•„ì›ƒì†Œì‹±ë¹„", "ì™¸ì£¼ë¹„", "ìš©ì—­ìˆ˜ìˆ˜ë£Œ"], "ê²½ë¹„"),
            63: AccountItem(63, "ì„¸ê¸ˆê³¼ê³µê³¼", ["ì„¸ê¸ˆ", "ê³µê³¼ê¸ˆ", "ì¡°ì„¸ê³µê³¼"], "ê²½ë¹„"),
            64: AccountItem(64, "ì„ì°¨ë£Œ", ["ì„ëŒ€ë£Œ", "ë¶€ë™ì‚°ì„ì°¨ë£Œ", "ë¦¬ìŠ¤ë£Œ"], "ê²½ë¹„"),
            65: AccountItem(65, "ê°ê°€ìƒê°ë¹„", ["ìœ í˜•ìì‚°ê°ê°€ìƒê°ë¹„", "ê°ê°€ìƒê°"], "ê²½ë¹„"),
            66: AccountItem(66, "ë¬´í˜•ìì‚°ìƒê°ë¹„", ["ë¬´í˜•ìì‚°ìƒê°", "ì†Œí”„íŠ¸ì›¨ì–´ìƒê°"], "ê²½ë¹„"),
            67: AccountItem(67, "ê¸°íƒ€ê²½ë¹„", ["ê¸°íƒ€íŒê´€ë¹„", "ì¡ë¹„"], "ê²½ë¹„"),
            68: AccountItem(68, "ëŒ€ì¶œê¸ˆ í‰ì”(ì–µì›)", ["ëŒ€ì¶œí‰ì”", "í‰ê· ëŒ€ì¶œì”ì•¡"], "ê²½ë¹„"),
            
            # ì¸ê±´ë¹„
            71: AccountItem(71, "ì¸ê±´ë¹„ ì´ê³„", ["ì¸ê±´ë¹„", "ê¸‰ì—¬ì´ì•¡", "ì¸ê±´ë¹„í•©ê³„"], "ì¸ê±´ë¹„"),
            72: AccountItem(72, "ì¸ê±´ë¹„", ["ê¸‰ì—¬", "ì„ê¸ˆ", "ë³´ìˆ˜"], "ì¸ê±´ë¹„"),
            73: AccountItem(73, "ë³µë¦¬í›„ìƒë¹„", ["ë³µì§€ë¹„", "ë³µë¦¬ë¹„", "í›„ìƒë¹„"], "ì¸ê±´ë¹„"),
            74: AccountItem(74, "í‰ê·  ì§ì›ìˆ˜", ["ì§ì›ìˆ˜", "ì¢…ì—…ì›ìˆ˜", "ì„ì§ì›ìˆ˜"], "ì¸ê±´ë¹„"),
            75: AccountItem(75, "ì¸ë‹¹ ì¸ê±´ë¹„", ["1ì¸ë‹¹ì¸ê±´ë¹„", "í‰ê· ì¸ê±´ë¹„"], "ì¸ê±´ë¹„"),
            
            # ê²½ì˜ì§€í‘œ
            8: AccountItem(8, "ì˜ˆëŒ€ë§ˆì§„ìœ¨", ["ì˜ˆëŒ€ë§ˆì§„", "NIM", "ìˆœì´ìë§ˆì§„"], "ê²½ì˜ì§€í‘œ"),
            11: AccountItem(11, "BIS", ["BISë¹„ìœ¨", "ìê¸°ìë³¸ë¹„ìœ¨"], "ê²½ì˜ì§€í‘œ"),
            12: AccountItem(12, "ê³ ì •ì´í•˜ì—¬ì‹ ë¹„ìœ¨", ["ê³ ì •ì´í•˜ë¹„ìœ¨", "ë¶€ì‹¤ì—¬ì‹ ë¹„ìœ¨"], "ê²½ì˜ì§€í‘œ"),
            13: AccountItem(13, "ì—°ì²´ìœ¨", ["ì—°ì²´ìœ¨", "ëŒ€ì¶œì—°ì²´ìœ¨"], "ê²½ì˜ì§€í‘œ"),
            23: AccountItem(23, "BISë¹„ìœ¨(ìƒì„¸)", ["ê¸°ë³¸ìë³¸ë¹„ìœ¨", "ë³´ì™„ìë³¸ë¹„ìœ¨"], "ê²½ì˜ì§€í‘œ"),
            58: AccountItem(58, "ëŒ€ì†ìƒê°ë¹„ìœ¨", ["ëŒ€ì†ë¹„ìœ¨", "ìƒê°ë¥ "], "ê²½ì˜ì§€í‘œ"),
            69: AccountItem(69, "ëŒ€ì¶œê¸ˆ í‰ì” æ¯” ê²½ë¹„ìœ¨", ["ê²½ë¹„ìœ¨", "ì˜ì—…ê²½ë¹„ìœ¨"], "ê²½ì˜ì§€í‘œ"),
            70: AccountItem(70, "ëŒ€ì¶œê¸ˆ í‰ì” æ¯” ê´‘ê³ ë¹„ìœ¨", ["ê´‘ê³ ë¹„ìœ¨", "ë§ˆì¼€íŒ…ë¹„ìœ¨"], "ê²½ì˜ì§€í‘œ"),
        }
        
        return items
    
    def extract_from_md(self, md_content: str) -> Dict:
        """MD íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        logger.info("="*50)
        logger.info("MD íŒŒì¼ ë¶„ì„ ì‹œì‘")
        logger.info(f"ë¬¸ì„œ í¬ê¸°: {len(md_content)} ë¬¸ì")
        
        # ì´ˆê¸°í™”
        self.extracted_data = {}
        
        # ì§„í–‰ ìƒíƒœ í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # 1. ë¬¸ì„œ êµ¬ì¡° íŒŒì•…
        status_text.text("ğŸ“„ ë¬¸ì„œ êµ¬ì¡° íŒŒì•… ì¤‘...")
        progress_bar.progress(0.1)
        sections = self._parse_document_structure(md_content)
        
        # 2. ì¬ë¬´ì œí‘œ ë³¸ë¬¸ ì¶”ì¶œ
        status_text.text("ğŸ’° ì¬ë¬´ì œí‘œ ë³¸ë¬¸ ì¶”ì¶œ ì¤‘...")
        progress_bar.progress(0.3)
        self._extract_financial_statements(sections)
        
        # 3. ì£¼ì„ ì¶”ì¶œ ë° ì—°ê³„
        status_text.text("ğŸ“ ì£¼ì„ ì¶”ì¶œ ë° ì—°ê³„ ì¤‘...")
        progress_bar.progress(0.5)
        self._extract_and_link_notes(sections)
        
        # 4. ëˆ„ë½ í•­ëª© ì¬íƒìƒ‰
        status_text.text("ğŸ” ëˆ„ë½ í•­ëª© ì¬íƒìƒ‰ ì¤‘...")
        progress_bar.progress(0.7)
        self._search_missing_items(md_content)
        
        # 5. ê³„ì‚° ê°€ëŠ¥ í•­ëª© ì²˜ë¦¬
        status_text.text("ğŸ§® ê³„ì‚° ê°€ëŠ¥ í•­ëª© ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(0.9)
        self._calculate_derived_items()
        
        # ì™„ë£Œ
        status_text.text("âœ… ì¶”ì¶œ ì™„ë£Œ!")
        progress_bar.progress(1.0)
        
        return self.extracted_data
    
    def _parse_document_structure(self, content: str) -> Dict[str, str]:
        """ë¬¸ì„œ êµ¬ì¡° íŒŒì‹±"""
        sections = {}
        
        # ì£¼ìš” ì„¹ì…˜ íŒ¨í„´
        patterns = {
            'ì¬ë¬´ìƒíƒœí‘œ': [
                r'ì¬\s*ë¬´\s*ìƒ\s*íƒœ\s*í‘œ',
                r'ìš”\s*ì•½\s*ë¶„\s*ê¸°\s*ì¬\s*ë¬´\s*ìƒ\s*íƒœ\s*í‘œ',
                r'Statement\s+of\s+Financial\s+Position',
            ],
            'ì†ìµê³„ì‚°ì„œ': [
                r'ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ',
                r'ìš”\s*ì•½\s*ë¶„\s*ê¸°\s*ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ',
                r'Income\s+Statement',
            ],
            'ì£¼ì„': [
                r'ì£¼\s*ì„',
                r'ì£¼ì„\s*\d+',
                r'Notes?\s+to\s+Financial\s+Statements?',
            ],
        }
        
        # ì„¹ì…˜ ì°¾ê¸°
        for section_name, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = list(re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE))
                if matches:
                    start = matches[0].start()
                    # ë‹¤ìŒ ì„¹ì…˜ ì°¾ê¸°
                    next_section = len(content)
                    for other_section, other_patterns in patterns.items():
                        if other_section != section_name:
                            for other_pattern in other_patterns:
                                next_matches = list(re.finditer(other_pattern, content[start+100:], re.IGNORECASE))
                                if next_matches:
                                    next_section = min(next_section, start + 100 + next_matches[0].start())
                    
                    sections[section_name] = content[start:next_section]
                    break
        
        # ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ë¬¸ì„œ ì‚¬ìš©
        if not sections:
            sections['ì „ì²´ë¬¸ì„œ'] = content
            
        return sections
    
    def _extract_financial_statements(self, sections: Dict[str, str]):
        """ì¬ë¬´ì œí‘œ ë³¸ë¬¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        for section_name, content in sections.items():
            if 'ì¬ë¬´ìƒíƒœí‘œ' in section_name:
                self._extract_balance_sheet(content)
            elif 'ì†ìµê³„ì‚°ì„œ' in section_name:
                self._extract_income_statement(content)
    
    def _extract_balance_sheet(self, content: str):
        """ì¬ë¬´ìƒíƒœí‘œ ë°ì´í„° ì¶”ì¶œ"""
        # MD í…Œì´ë¸” í˜•ì‹ ì²˜ë¦¬
        if '|' in content:
            self._extract_from_md_table(content, "ì¬ë¬´ìƒíƒœí‘œ")
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹ ì²˜ë¦¬
        self._extract_with_patterns(content, "ì¬ë¬´ìƒíƒœí‘œ")
    
    def _extract_income_statement(self, content: str):
        """ì†ìµê³„ì‚°ì„œ ë°ì´í„° ì¶”ì¶œ"""
        # MD í…Œì´ë¸” í˜•ì‹ ì²˜ë¦¬
        if '|' in content:
            self._extract_from_md_table(content, "ì†ìµê³„ì‚°ì„œ")
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹ ì²˜ë¦¬
        self._extract_with_patterns(content, "ì†ìµê³„ì‚°ì„œ")
    
    def _extract_from_md_table(self, content: str, section_name: str):
        """MD í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        lines = content.split('\n')
        tables = []
        current_table = []
        in_table = False
        
        for line in lines:
            if '|' in line:
                if not re.match(r'^\s*\|[\s\-:]+\|', line):
                    cells = [cell.strip() for cell in re.split(r'\s*\|\s*', line)]
                    cells = [c for c in cells if c]
                    if cells:
                        current_table.append(cells)
                        in_table = True
                elif in_table and current_table:
                    tables.append(current_table)
                    current_table = []
            elif in_table and current_table:
                tables.append(current_table)
                current_table = []
                in_table = False
        
        if current_table:
            tables.append(current_table)
        
        # ê° í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        for table in tables:
            for row in table:
                if len(row) >= 2:
                    self._match_account_in_row(row, section_name)
    
    def _extract_with_patterns(self, content: str, section_name: str):
        """íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ"""
        patterns = [
            r'([ê°€-í£\s\(\)]+)\s+([\d,]+)\s*(?:ì²œì›|ë°±ë§Œì›|ì–µì›)?',
            r'([ê°€-í£\s\(\)]+)\s*[:ï¼š]\s*([\d,]+)',
            r'([ê°€-í£\s\(\)]+)\s*(?:\(ì£¼\d+\))?\s*([\d,]+)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                account_text = match[0].strip()
                value_text = match[1].strip()
                self._match_account(account_text, value_text, section_name)
    
    def _match_account_in_row(self, row: List[str], source: str):
        """í…Œì´ë¸” í–‰ì—ì„œ ê³„ì • ë§¤ì¹­"""
        account_name = row[0]
        
        for item_id, account in self.account_items.items():
            if item_id in self.extracted_data:
                continue
                
            for name in [account.name] + account.aliases:
                if self._is_similar(name, account_name):
                    for cell in row[1:]:
                        if re.search(r'[\d,]+', cell):
                            value = re.search(r'([\d,]+)', cell).group(1)
                            self.extracted_data[item_id] = {
                                'name': account.name,
                                'value': value,
                                'source': source
                            }
                            break
                    break
    
    def _match_account(self, account_text: str, value_text: str, source: str):
        """ê³„ì •ëª…ê³¼ ê°’ ë§¤ì¹­"""
        for item_id, account in self.account_items.items():
            if item_id in self.extracted_data:
                continue
                
            for name in [account.name] + account.aliases:
                if self._is_similar(name, account_text):
                    self.extracted_data[item_id] = {
                        'name': account.name,
                        'value': value_text,
                        'source': source
                    }
                    break
    
    def _is_similar(self, name1: str, name2: str) -> bool:
        """ë¬¸ìì—´ ìœ ì‚¬ë„ ì²´í¬"""
        # ê³µë°± ì œê±°
        norm1 = re.sub(r'\s+', '', name1)
        norm2 = re.sub(r'\s+', '', name2)
        
        # ì™„ì „ ì¼ì¹˜
        if norm1 == norm2:
            return True
        
        # ë¶€ë¶„ ë¬¸ìì—´
        if norm1 in norm2 or norm2 in norm1:
            return True
        
        # Fuzzy ë§¤ì¹­
        return fuzz.ratio(name1, name2) >= 80
    
    def _extract_and_link_notes(self, sections: Dict[str, str]):
        """ì£¼ì„ ì¶”ì¶œ ë° ì—°ê³„"""
        if 'ì£¼ì„' in sections:
            # ì£¼ì„ ë‚´ìš©ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            self._extract_with_patterns(sections['ì£¼ì„'], 'ì£¼ì„')
    
    def _search_missing_items(self, full_content: str):
        """ëˆ„ë½ëœ í•­ëª© ì¬íƒìƒ‰"""
        # ëª¨ë“  ê°€ëŠ¥í•œ ê³„ì • ì¶”ì¶œ
        patterns = [
            r'([ê°€-í£\s\(\)]+)\s*[:ï¼š]?\s*([\d,]+)\s*(?:ì²œì›|ë°±ë§Œì›|ì–µì›)?',
            r'\|\s*([ê°€-í£\s\(\)]+)\s*\|\s*([\d,]+)',
        ]
        
        all_accounts = []
        for pattern in patterns:
            matches = re.findall(pattern, full_content, re.MULTILINE)
            all_accounts.extend(matches)
        
        # Fuzzy matchingìœ¼ë¡œ ëˆ„ë½ í•­ëª© ì°¾ê¸°
        for item_id, account in self.account_items.items():
            if item_id in self.extracted_data:
                continue
                
            best_match = None
            best_score = 0
            
            for found_name, found_value in all_accounts:
                for name in [account.name] + account.aliases:
                    score = fuzz.ratio(name, found_name.strip())
                    if score > best_score and score >= 70:
                        best_score = score
                        best_match = (found_name, found_value)
            
            if best_match:
                self.extracted_data[item_id] = {
                    'name': account.name,
                    'value': best_match[1],
                    'matched_name': best_match[0],
                    'similarity': best_score,
                    'source': 'Fuzzy Matching'
                }
    
    def _calculate_derived_items(self):
        """ê³„ì‚° ê°€ëŠ¥í•œ í•­ëª© ì²˜ë¦¬"""
        # ì˜ˆëŒ€ë§ˆì§„ìœ¨ ê³„ì‚°
        if 6 in self.extracted_data and 7 in self.extracted_data:
            try:
                ì´ììˆ˜ìµ = float(self.extracted_data[6]['value'].replace(',', ''))
                ì´ìë¹„ìš© = float(self.extracted_data[7]['value'].replace(',', ''))
                if ì´ììˆ˜ìµ > 0:
                    ì˜ˆëŒ€ë§ˆì§„ìœ¨ = (ì´ììˆ˜ìµ - ì´ìë¹„ìš©) / ì´ììˆ˜ìµ * 100
                    self.extracted_data[8] = {
                        'name': 'ì˜ˆëŒ€ë§ˆì§„ìœ¨',
                        'value': f"{ì˜ˆëŒ€ë§ˆì§„ìœ¨:.2f}",
                        'source': 'ê³„ì‚°ê°’'
                    }
            except:
                pass
    
    def generate_report(self) -> pd.DataFrame:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        report_data = []
        
        for item_id in sorted(self.account_items.keys()):
            account = self.account_items[item_id]
            
            if item_id in self.extracted_data:
                data = self.extracted_data[item_id]
                report_data.append({
                    'ID': item_id,
                    'ê³„ì •ëª…': account.name,
                    'ì¹´í…Œê³ ë¦¬': account.category,
                    'ê°’': data['value'],
                    'ì¶œì²˜': data['source'],
                    'ìƒíƒœ': 'ì¶”ì¶œì™„ë£Œ'
                })
            else:
                report_data.append({
                    'ID': item_id,
                    'ê³„ì •ëª…': account.name,
                    'ì¹´í…Œê³ ë¦¬': account.category,
                    'ê°’': 'N/A',
                    'ì¶œì²˜': 'ë¯¸ë°œê²¬',
                    'ìƒíƒœ': 'N/A'
                })
        
        return pd.DataFrame(report_data)


# AI ì¶”ì¶œ ê¸°ëŠ¥ (ì˜µì…˜)
class AIEnhancedExtractor:
    """OpenAI APIë¥¼ í™œìš©í•œ ì¶”ì¶œ ê¸°ëŠ¥"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        openai.api_key = api_key
        
    def extract_with_ai(self, md_content: str, missing_items: List[Dict]) -> Dict:
        """AIë¥¼ í™œìš©í•œ ëˆ„ë½ í•­ëª© ì¶”ì¶œ"""
        if not self.api_key:
            return {}
            
        try:
            # ëˆ„ë½ëœ í•­ëª©ë“¤ë§Œ ì¶”ì¶œ ìš”ì²­
            prompt = self._create_prompt(md_content[:3000], missing_items)
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ì¬ë¬´ì œí‘œì—ì„œ ê³„ì • í•­ëª©ê³¼ ê°’ì„ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)
            return result.get("extracted_items", {})
            
        except Exception as e:
            st.error(f"AI ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {}
    
    def _create_prompt(self, content: str, missing_items: List[Dict]) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        items_text = "\n".join([f"- ID {item['id']}: {item['name']}" for item in missing_items[:10]])
        
        return f"""
ë‹¤ìŒ ì¬ë¬´ì œí‘œì—ì„œ ì•„ë˜ í•­ëª©ë“¤ì˜ ê°’ì„ ì°¾ì•„ì£¼ì„¸ìš”:

{items_text}

ë¬¸ì„œ:
{content}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "extracted_items": {{
        "í•­ëª©ID": {{"value": "ê°’", "unit": "ë‹¨ìœ„"}}
    }}
}}
"""


# Streamlit ë©”ì¸ ì•±
def main():
    """Streamlit ë©”ì¸ í•¨ìˆ˜"""
    st.title("ğŸ’° ì¬ë¬´ì •ë³´ ì¶”ì¶œê¸°")
    st.markdown("### MD íŒŒì¼ì—ì„œ ì €ì¶•ì€í–‰ ì¬ë¬´ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # AI ê¸°ëŠ¥ ì„¤ì •
        use_ai = st.checkbox("AI ì¶”ì¶œ ê¸°ëŠ¥ ì‚¬ìš©", value=False)
        api_key = ""
        
        if use_ai:
            api_key = st.text_input("OpenAI API Key", type="password", 
                                   help="ëˆ„ë½ëœ í•­ëª©ì„ AIë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤")
            if api_key:
                st.success("âœ… API Key ì…ë ¥ë¨")
            else:
                st.warning("âš ï¸ API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        
        st.markdown("---")
        st.markdown("### ğŸ“Š ì¶”ì¶œ ê°€ëŠ¥ í•­ëª©")
        st.markdown("ì´ **75ê°œ** í‘œì¤€ ê³„ì • í•­ëª©")
        st.markdown("- ì¬ë¬´ìƒíƒœí‘œ: 11ê°œ")
        st.markdown("- ì†ìµê³„ì‚°ì„œ: 18ê°œ")
        st.markdown("- ê²½ì˜ì§€í‘œ: 8ê°œ")
        st.markdown("- ê¸°íƒ€: 38ê°œ")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "MD íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['md'],
        help="PDFì—ì„œ ë³€í™˜ëœ MD íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_file is not None:
        # íŒŒì¼ ì½ê¸°
        md_content = uploaded_file.read().decode('utf-8')
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("íŒŒì¼ëª…", uploaded_file.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{len(md_content):,} ë¬¸ì")
        with col3:
            st.metric("ì˜ˆìƒ ì‹œê°„", "ì•½ 10ì´ˆ")
        
        # ì¶”ì¶œ ë²„íŠ¼
        if st.button("ğŸš€ ì¶”ì¶œ ì‹œì‘", type="primary"):
            # ì¶”ì¶œê¸° ìƒì„±
            extractor = FinancialDataExtractor()
            
            # ì¶”ì¶œ ì‹¤í–‰
            with st.spinner("ì¶”ì¶œ ì§„í–‰ ì¤‘..."):
                extracted_data = extractor.extract_from_md(md_content)
                
                # AI ì¶”ì¶œ (ì˜µì…˜)
                if use_ai and api_key:
                    # ëˆ„ë½ í•­ëª© í™•ì¸
                    missing_items = []
                    for item_id, account in extractor.account_items.items():
                        if item_id not in extracted_data:
                            missing_items.append({
                                'id': item_id,
                                'name': account.name
                            })
                    
                    if missing_items:
                        st.info(f"ğŸ¤– AIë¡œ {len(missing_items)}ê°œ ëˆ„ë½ í•­ëª© ì¶”ì¶œ ì‹œë„...")
                        ai_extractor = AIEnhancedExtractor(api_key)
                        ai_results = ai_extractor.extract_with_ai(md_content, missing_items)
                        
                        # AI ê²°ê³¼ ë³‘í•©
                        for item_id, data in ai_results.items():
                            if int(item_id) not in extracted_data:
                                extracted_data[int(item_id)] = {
                                    'name': extractor.account_items[int(item_id)].name,
                                    'value': data['value'],
                                    'source': 'AI ì¶”ì¶œ'
                                }
            
            # ë³´ê³ ì„œ ìƒì„±
            report = extractor.generate_report()
            
            # ê²°ê³¼ í‘œì‹œ
            st.success("âœ… ì¶”ì¶œ ì™„ë£Œ!")
            
            # í†µê³„ í‘œì‹œ
            total_items = len(report)
            extracted_items = len(report[report['ìƒíƒœ'] == 'ì¶”ì¶œì™„ë£Œ'])
            extraction_rate = (extracted_items / total_items) * 100
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì „ì²´ í•­ëª©", f"{total_items}ê°œ")
            with col2:
                st.metric("ì¶”ì¶œ ì„±ê³µ", f"{extracted_items}ê°œ", 
                         delta=f"{extracted_items - (total_items - extracted_items)}")
            with col3:
                st.metric("ì¶”ì¶œë¥ ", f"{extraction_rate:.1f}%",
                         delta=f"{extraction_rate - 50:.1f}%")
            with col4:
                st.metric("N/A í•­ëª©", f"{total_items - extracted_items}ê°œ")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            st.markdown("### ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì¶œ í˜„í™©")
            
            category_stats = report[report['ìƒíƒœ'] == 'ì¶”ì¶œì™„ë£Œ'].groupby('ì¹´í…Œê³ ë¦¬').size()
            category_total = report.groupby('ì¹´í…Œê³ ë¦¬').size()
            
            category_df = pd.DataFrame({
                'ì¶”ì¶œ': category_stats,
                'ì „ì²´': category_total
            }).fillna(0)
            category_df['ì¶”ì¶œë¥ '] = (category_df['ì¶”ì¶œ'] / category_df['ì „ì²´'] * 100).round(1)
            
            st.bar_chart(category_df[['ì¶”ì¶œ', 'ì „ì²´']])
            
            # ê²°ê³¼ í…Œì´ë¸”
            st.markdown("### ğŸ“‹ ì¶”ì¶œ ê²°ê³¼")
            
            # í•„í„°ë§ ì˜µì…˜
            col1, col2 = st.columns([1, 3])
            with col1:
                show_all = st.checkbox("ëª¨ë“  í•­ëª© í‘œì‹œ", value=False)
            with col2:
                category_filter = st.multiselect(
                    "ì¹´í…Œê³ ë¦¬ í•„í„°",
                    options=report['ì¹´í…Œê³ ë¦¬'].unique(),
                    default=[]
                )
            
            # ë°ì´í„° í•„í„°ë§
            filtered_report = report.copy()
            if not show_all:
                filtered_report = filtered_report[filtered_report['ìƒíƒœ'] == 'ì¶”ì¶œì™„ë£Œ']
            if category_filter:
                filtered_report = filtered_report[filtered_report['ì¹´í…Œê³ ë¦¬'].isin(category_filter)]
            
            # í…Œì´ë¸” í‘œì‹œ
            st.dataframe(
                filtered_report,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "ID": st.column_config.NumberColumn("ID", width="small"),
                    "ê³„ì •ëª…": st.column_config.TextColumn("ê³„ì •ëª…", width="medium"),
                    "ì¹´í…Œê³ ë¦¬": st.column_config.TextColumn("ì¹´í…Œê³ ë¦¬", width="small"),
                    "ê°’": st.column_config.TextColumn("ê°’", width="medium"),
                    "ì¶œì²˜": st.column_config.TextColumn("ì¶œì²˜", width="small"),
                    "ìƒíƒœ": st.column_config.TextColumn("ìƒíƒœ", width="small")
                }
            )
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.markdown("### ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Excel ë‹¤ìš´ë¡œë“œ
                excel_buffer = io.BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                    report.to_excel(writer, index=False, sheet_name='ì¶”ì¶œê²°ê³¼')
                excel_buffer.seek(0)
                
                st.download_button(
                    label="ğŸ“Š Excel ë‹¤ìš´ë¡œë“œ",
                    data=excel_buffer,
                    file_name=f"{uploaded_file.name.replace('.md', '')}_ì¶”ì¶œê²°ê³¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
            with col2:
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = report.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"{uploaded_file.name.replace('.md', '')}_ì¶”ì¶œê²°ê³¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            
            # ì¶”ì¶œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ” ì¶”ì¶œëœ ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
                st.json(extracted_data)


if __name__ == "__main__":
    main()
